{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Photogrammetry: Part 1\n",
    "## Inverting the Camera model\n",
    "\n",
    "You'll recall that back in Project 1, I put a \"bonus\" problem at the bottom.  The question posed was thus:\n",
    "\n",
    "A calibrated camera model is a non-linear function that maps from a 3D coordinate system to a 2D coordinate system.  Can this function be inverted?  Can you, based on a 2D image of an object, recover that object's 3D coordinates?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "I_1 = plt.imread('campus_stereo_1.jpg')\n",
    "I_2 = plt.imread('campus_stereo_2.jpg')\n",
    "\n",
    "gcp_1 = np.loadtxt('gcp_stereo_1.txt',delimiter=',')\n",
    "gcp_2 = np.loadtxt('gcp_stereo_2.txt',delimiter=',')\n",
    "fig,axs = plt.subplots(nrows=1,ncols=2)\n",
    "axs[0].imshow(I_1)\n",
    "axs[0].plot(gcp_1[:,0],gcp_1[:,1],'ro')\n",
    "\n",
    "axs[1].imshow(I_2)\n",
    "axs[1].plot(gcp_2[:,0],gcp_2[:,1],'ro')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calibrating camera models is easy: we have already produced code that allows us to do it.  You'll remember that the solution to this problem is essentially a *non-linear* least squares problem, the solution of which is the optimal camera pose $\\mathbf{p}_{opt}$:\n",
    "$$\n",
    "\\mathbf{p}_{opt} = \\mathrm{argmin}_{\\mathbf{p}} \\frac{1}{2} \\sum_{i=1}^n \\sum_{j=1}^2 (f(\\mathbf{X}_i,\\mathbf{p})_j - \\mathbf{u}_{ij})^2,\n",
    "$$\n",
    "where $n$ is the number of GCPs, and $f(\\mathbf{X},\\mathbf{p})$ is the projection of real world coordinates $\\mathbf{X}$ into camera coordinates (which depends on the pose $\\mathbf{p}$, and $\\mathbf{u}$ is the pixel coordinates of the equivalent point in the image.\n",
    "\n",
    "Stated plainly, the objective function above corresponds to the situation in which the real world coordinates of ground control points and their locations in the image are known, while the camera parameters are unknown (and are what we are trying to determine).  What we would like to do is to write an objective function for the converse situation, in which the camera parameters are known, the position of a desired object in an image is known, but the real world coordinates are unknown (and are what we are trying to determine).  Such an objective function might look like this:\n",
    "$$\n",
    "\\mathbf{X}_{opt} = \\mathrm{argmin}_{\\mathbf{X}} \\frac{1}{2} \\sum_{j=1}^2 (f(\\mathbf{X},\\mathbf{p})_j - \\mathbf{u}_j)^2,\n",
    "$$\n",
    "where $X_{opt}$ is the position of an object in real world coordinates, $\\mathbf{u}$ is its known coordinates in the image, and $\\mathbf{p}$ is a known camera model.  Unfortunately, using this objective function is doomed to failure.  Why can't this work?  Counting the number of data points, we find that there are two, the two components of $\\mathbf{u}$.  However, the vector $\\mathbf{X}$ has three components.  The system is underdetermined: we can only determine $\\mathbf{X}$ up to a constant scaling factor.  \n",
    "\n",
    "How can we make this system of equations over-determined instead?  We can use more cameras, of course.  How does this affect the objective function: \n",
    "$$\n",
    "\\mathbf{X}_{opt} = \\mathrm{argmin}_{\\mathbf{X}} \\frac{1}{2} \\sum_{i=1}^m \\sum_{j=1}^2 (f(\\mathbf{X},\\mathbf{p}_i)_j - \\mathbf{u}_{ij})^2,\n",
    "$$\n",
    "where $m$ is the number of cameras, $\\mathbf{p}_i$ is the known pose of camera $i$, and $\\mathbf{u}_i$ is the location of the feature of interest in the image corresponding to camera $i$.  As in the case of solving for pose, this problem can be solved using Levenburg-Marquardt.  \n",
    "\n",
    "## Assignment\n",
    "**In the project file you will find two images (campus_stereo_1.jpg and campus_stereo_2.jpg), with two sets of ground control points (gcp_stereo_1.jpg and gcp_stereo_2.jpg).  Optimze a camera model for each image.  Using both these camera models, implement the optimization problem defined above for determining the [Easting,Northing,Elevation] position of the central pivot on the main hall clock.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCP [1984.76072662, 1053.33790893, 272558.68, 5193938.07, 1015.0]\n"
     ]
    }
   ],
   "source": [
    "# Import camera class\n",
    "from camera import Camera\n",
    "roll_init = np.radians(0.0)\n",
    "pitch_init = np.radians(0.0)\n",
    "yaw_init = np.radians(90.0)\n",
    "pose_0 = np.array([2.72e5, 5.193e6, 1000, roll_init, pitch_init, yaw_init])\n",
    "my_cam_1 = Camera()\n",
    "my_cam_2 = Camera()\n",
    "\n",
    "my_cam_1.f = (27/36)*3264 # Focal length\n",
    "my_cam_1.c = np.array([2448.,3264.]) # Sensor size\n",
    "my_cam_1.p = pose_0\n",
    "\n",
    "my_cam_2.f = (27/36)*3264 # Focal length\n",
    "my_cam_2.c = np.array([2448.,3264.]) # Sensor size\n",
    "my_cam_2.p = pose_0\n",
    "\n",
    "\n",
    "gcp_1 = gcp_1.tolist()\n",
    "gcp_2 = gcp_2.tolist()\n",
    "print(\"GCP\", gcp_1[0])\n",
    "opt_p1 = my_cam_1.estimate_pose(gcp_1)\n",
    "\n",
    "opt_p2 = my_cam_2.estimate_pose(gcp_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.72646874e+05 5.19397703e+06 1.02769936e+03 9.10174264e+01\n",
      " 4.44027753e+01 4.54364537e+01]\n",
      "[2.72624795e+05 5.19389723e+06 1.03229036e+03 9.12056642e+01\n",
      " 4.44866378e+01 4.61144192e+01]\n"
     ]
    }
   ],
   "source": [
    "# Pose of camera 1\n",
    "print(my_cam_1.p)\n",
    "\n",
    "# Pose of camera 2\n",
    "print(my_cam_2.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCP [1984.76072662, 1053.33790893, 272558.68, 5193938.07, 1015.0]\n",
      "[2063.62656016  990.69194944]\n",
      "[ 835.01648735 1932.23029385]\n",
      "[ 366.19215751 1248.49842524]\n",
      "[1296.84183746 1086.20315291]\n",
      "[2329.977817  1433.5269629]\n"
     ]
    }
   ],
   "source": [
    "print(\"GCP\", gcp_1[0])\n",
    "def f(X_gcp, p_opt, camera):\n",
    "    pts = X_gcp[0:2]\n",
    "    u_gcp = X_gcp[2:]\n",
    "    # Augment gcp by 1\n",
    "    u_gcp.append(1)\n",
    "    rotated = camera.rotational_transform(p_opt, u_gcp)\n",
    "    projected = camera.projective_transform(rotated)\n",
    "    \n",
    "    return projected\n",
    "\n",
    "\n",
    "X_opt = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
